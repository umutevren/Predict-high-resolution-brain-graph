{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa74ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1501900(16_80_06)_0701(90403_40430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c057e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as r\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mad\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2a6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X_train, X_test, n_components=None):\n",
    "    if n_components == None: # If no parameter has been provided\n",
    "        # minimum(n_samples, 2% of n_features)\n",
    "        n_components = min(len(X_train), int(np.ceil(0.02*len(X_train.iloc[0]))))\n",
    "    \n",
    "    # Define PCA and model according to training set\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(X_train)\n",
    "    \n",
    "    # Calculate and return feature-extracted datasets\n",
    "    return pca.transform(X_train), pca.transform(X_test)\n",
    "\n",
    "def predict_super_resolution(X_train, Y_train, X_test):\n",
    "    X_train, X_test = preprocessing(X_train, X_test)\n",
    "    \n",
    "    model = LinearRegression().fit(X_train, Y_train)\n",
    "    \n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d01bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(results, file_name):\n",
    "    results = results.flatten()\n",
    "    \n",
    "    open(file_name, \"w\").close() # Create blank file\n",
    "    file = open(file_name, \"a\") # Open with appending\n",
    "    \n",
    "    # Write header row\n",
    "    file.write(\"ID,predicted\\n\")\n",
    "    \n",
    "    i = 0 # Write results\n",
    "    for value in results:\n",
    "        file.write(f\"{i},{value}\\n\")\n",
    "        i += 1\n",
    "    \n",
    "    file.close()\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4acfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_5_Fold(train_LR_location, train_HR_location):\n",
    "    # Read data\n",
    "    X_train = pd.read_csv(train_LR_location)\n",
    "    Y_train = pd.read_csv(train_HR_location)\n",
    "\n",
    "    r.seed(1) # Define cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    predictions = np.array([])\n",
    "    ground_truth = np.array([])\n",
    "\n",
    "    MSE_values = []\n",
    "    MAD_values = []\n",
    "    P_corr_values = []\n",
    "\n",
    "    i = 0\n",
    "    for i_train, i_test in kf.split(X_train): # For each split\n",
    "        current_X_train = X_train.iloc[i_train] # Get training input\n",
    "        current_Y_train = Y_train.iloc[i_train] # Get training output\n",
    "        current_X_test = X_train.iloc[i_test]   # Get testing input\n",
    "\n",
    "        # Get testing output\n",
    "        current_ground_truth = Y_train.iloc[i_test].to_numpy().flatten()\n",
    "        ground_truth = np.concatenate([ground_truth, current_ground_truth])\n",
    "\n",
    "        # Calculate predictions\n",
    "        current_predictions = predict_super_resolution(current_X_train, current_Y_train, current_X_test).flatten()\n",
    "        predictions = np.concatenate([predictions, current_predictions])\n",
    "\n",
    "        # Calculate performance parameters\n",
    "        MSE_values += [mse(current_predictions, current_ground_truth)]\n",
    "        \n",
    "        # Used for report\n",
    "        #MAD_values += [mad(current_predictions, current_ground_truth)]\n",
    "        #P_corr_values += [pearsonr(current_predictions, current_ground_truth)[0]]\n",
    "    return predictions, MSE_values, MAD_values, P_corr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e96951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6762042"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, MSE_values, MAD_values, P_corr_values = CV_5_Fold(\"../data/train_LR.csv\", \"../data/train_HR.csv\")\n",
    "\n",
    "write_results(predictions, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "368fa9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187060429565174"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
